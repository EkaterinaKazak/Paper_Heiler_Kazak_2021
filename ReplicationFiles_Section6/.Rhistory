plot(vX, f(vX), type = "l", ylim = c(-0.8,0.8))
abline(v = r1, col = "red")
abline(v = r2, col = "red")
plot(vX, f_prime(vX), type = "l")
abline(h = 0, col = "blue")
abline(v = r1, col = "red")
abline(v = r2, col = "red")
# Newton's method for optimization: Example
f <- function(dX) {
dOut = 2 * dX * (dX - 1)^2 * (dX + 2)
return(dOut)
}
vX <- seq(-2, 2, 0.001)
plot(vX, f(vX), type = "l")
f_prime <- function(dX) {
dOut = 4 - 12 * dX + 8 * dX^3
return(dOut)
}
f_sec <- function(dX) {
dOut = 24 * dX^2 - 12
return(dOut)
}
#Newton's method function
NM <- function(f, f_prime, f_sec, dX0, dTol = 1e-9, n.max = 1000){
dX <- dX0
fx <- f(dX)
fpx <- f_prime(dX)
fsx <- f_sec(dX)
n <- 0
while ((abs(fpx) > dTol) && (n < n.max)) {
dX <- dX - fpx/fsx
fx <- f(dX)
fpx <- f_prime(dX)
fsx <- f_sec(dX)
n <- n + 1
cat("At iteration", n, "the value of x is:", dX, "\n")
}
if (n == n.max) {
cat('newton failed to converge\n')
} else {
return(dX)
}
}
# x0 = -2
NM(f, f_prime, f_sec, dX0 = -2)
plot(vX, f(vX), type = "l")
abline(v = -2, col = "blue") #initial value x_0
abline(v = -1.5714286, lty = 2) #x_1
abline(v = -1.3982235, lty = 2) #x_2
abline(v = -1.367014, lty = 2) #x_3
abline(v = -1.3660264, lty = 2) #x_4
abline(v = -1.3660254, col = "red") #x_5 final value
# x0 = 1.5
NM(f, f_prime, f_sec, dX0 = 1.5)
plot(vX, f(vX), type = "l")
abline(v = 1.5, col = "blue") #initial value x_0
abline(v = 1.19047619047619, lty = 2) #x_1
abline(v = 1.04457786410815, lty = 2) #x_2
abline(v = 1.00346150187496, lty = 2) #x_3
abline(v = 1.00002369070203, lty = 2) #x_4
abline(v = 1.00000000112241, lty = 2) #x_5
abline(v = 1, col = "red") #x_6 final value
# x0 = -0.4
NM(f, f_prime, f_sec, dX0 = -0.4)
plot(vX, f(vX), type = "l")
abline(v = -0.4, col = "blue") #initial value x_0
abline(v = 0.61568627, lty = 2) #x_1
abline(v = 0.091579154, lty = 2) #x_2
abline(v = 0.33797834, lty = 2) #x_3
abline(v = 0.36531716, lty = 2) #x_4
abline(v = 0.3660249, lty = 2) #x_5
abline(v = 0.3660254, col = "red") #x_6 final value
### Golden-section Eample
# Golden-section function:
# applies the golden-section algorithm to maximise ftn
# we assume that ftn is a function of a single variable
# and that x.l < x.m < x.r and ftn(x.l), ftn(x.r) <= ftn(x.m)
#
# the algorithm iteratively refines x.l, x.r, and x.m and terminates
# when x.r - x.l <= tol, then returns x.m
# golden ratio plus one
gsection <- function(f, dX.l, dX.r, dX.m, dTol = 1e-9) {
# golden ratio plus one
dGR1 <- 1 + (1 + sqrt(5))/2
# successively refine x.l, x.r, and x.m
f.l <- f(dX.l)
f.r <- f(dX.r)
f.m <- f(dX.m)
while ((dX.r - dX.l) > dTol) {
if ((dX.r - dX.m) > (dX.m - dX.l)) {
dY <- dX.m + (dX.r - dX.m)/dGR1
f.y <- f(dY)
if (f.y >= f.m) {
dX.l <- dX.m
f.l <- f.m
dX.m <- dY
f.m <- f.y
} else {
dX.r <- dY
f.r <- f.y
}
} else {
dY <- dX.m - (dX.m - dX.l)/dGR1
f.y <- f(dY)
if (f.y >= f.m) {
dX.r <- dX.m
f.r <- f.m
dX.m <- dY
f.m <- f.y
} else {
dX.l <- dY
f.l <- f.y
}
}
}
return(dX.m)
}
gsection(f, dX.l = -1, dX.r = 1, dX.m = -0.5)
optimize(f, lower = -0.4, upper = 0.8, maximum = TRUE)
############# MULTI DIM ###################
## steepest ascend method
ascent <- function(f, grad.f, vX0, dTol = 1e-9, n.max = 100) {
vX.old <- vX0
vX <- line.search(f, vX0, grad.f(vX0))
n <- 1
while ((f(vX) - f(vX.old) > dTol) & (n < n.max)) {
vX.old <- vX
vX <- line.search(f, vX, grad.f(vX))
cat("at iteration", n, "the coordinates of x are", vX, "\n")
n <- n + 1
}
return(vX)
}
#line search
line.search <- function(f, vX, vY, dTol = 1e-9, dA.max = 2^5) {
# f is a real function that takes a vector of length d
# x and y are vectors of length d
# line.search uses gsection to find a >= 0 such that
# g(a) = f(x + a*y) has a local maximum at a,
# within a tolerance of tol
# if no local max is found then we use 0 or a.max for a
# the value returned is x + a*y
if (sum(abs(vY)) == 0) return(vX) # g(a) constant
g <- function(dA) return(f(vX + dA*vY))
# find a triple a.l < a.m < a.r such that
# g(a.l) <= g(a.m) and g(a.m) >= g(a.r)
# a.l
dA.l <- 0
g.l <- g(dA.l)
# a.m
dA.m <- 1
g.m <- g(dA.m)
while ((g.m < g.l) & (dA.m > dTol)) {
dA.m <- dA.m/2
g.m <- g(dA.m)
}
# if a suitable a.m was not found then use 0 for a
if ((dA.m <= dTol) & (g.m < g.l)) return(vX)
# a.r
dA.r <- 2*dA.m
g.r <- g(dA.r)
while ((g.m < g.r) & (dA.r < dA.max)) {
dA.m <- dA.r
g.m <- g.r
dA.r <- 2*dA.m
g.r <- g(dA.r)
}
# if a suitable a.r was not found then use a.max for a
if ((dA.r >= dA.max) & (g.m < g.r)) return(vX + dA.max*vY)
# apply golden-section algorithm to g to find a
dA <- gsection(g, dA.l, dA.r, dA.m)
return(vX + dA*vY)
}
### Example
f <- function(vX) {
dOut = sin(vX[1]^2/2 - vX[2]^2/4) * cos(2*vX[1] - exp(vX[2]))
return(dOut)
}
library(numDeriv)
grad.f <- function(vX) {
dX_prime.1 = cos(vX[1]^2/2 - vX[2]^2/4)*vX[1] * cos(2*vX[1] - exp(vX[2]))
dX_prime.2 = sin(vX[1]^2/2 - vX[2]^2/4) * (-sin(2*vX[1] - exp(vX[2]))*2)
dY_prime.1 = cos(vX[1]^2/2 - vX[2]^2/4)*(-vX[2]/2) * cos(2*vX[1] - exp(vX[2]))
dY_prime.2 = sin(vX[1]^2/2 - vX[2]^2/4) * sin(2*vX[1] - exp(vX[2]))*exp(vX[2])
vOut = c(dX_prime.1 + dX_prime.2, dY_prime.1 + dY_prime.2)
return(vOut)
}
grad(f, c(0, 0.5))
grad.f(c(0, 0.5))
ascent(f, grad.f, vX0 = c(0.1, 0.3))
ascent(f, grad.f, vX0 = c(0, 0.5))
## Newton's method in hihger dimensions
newton <- function(f3, vX0, dTol = 1e-9, n.max = 100) {
# Newton's method for optimisation, starting at x0
# f3 is a function that given x returns the list
# {f(x), grad f(x), Hessian f(x)}, for some f
vX <- vX0
f3.x <- f3(vX)
n <- 0
while ((max(abs(f3.x[[2]])) > dTol) & (n < n.max)) {
vX <- vX - solve(f3.x[[3]], f3.x[[2]])
f3.x <- f3(vX)
cat("At iteration", n, "the coordinates of x are", vX, "\n")
n <- n + 1
}
if (n == n.max) {
cat('newton failed to converge\n')
} else {
return(vX)
}
}
# ## Example
f3 <- function(vX) {
dA <- vX[1]^2/2 - vX[2]^2/4
dB <- 2*vX[1] - exp(vX[2])
f <- sin(dA)*cos(dB)
f1 <- cos(dA)*cos(dB)*vX[1] - sin(dA)*sin(dB)*2
f2 <- -cos(dA)*cos(dB)*vX[2]/2 + sin(dA)*sin(dB)*exp(vX[2])
f11 <- -sin(dA)*cos(dB)*(4 + vX[1]^2) + cos(dA)*cos(dB) -
cos(dA)*sin(dB)*4*vX[1]
f12 <- sin(dA)*cos(dB)*(vX[1]*vX[2]/2 + 2*exp(vX[2])) +
cos(dA)*sin(dB)*(vX[1]*exp(vX[2]) + vX[2])
f22 <- -sin(dA)*cos(dB)*(vX[2]^2/4 + exp(2*vX[2])) - cos(dA)*cos(dB)/2 -
cos(dA)*sin(dB)*vX[2]*exp(vX[2]) + sin(dA)*sin(dB)*exp(vX[2])
return(list(f, c(f1, f2), matrix(c(f11, f12, f12, f22), 2, 2)))
}
newton(f3, vX0 = c(1.6, 0.5))
newton(f3, vX0 = c(1.75, 0.25))
newton(f3, vX0 = c(1.6, 1.2))
f1 <- function(vX) {
dA <- vX[1]^2/2 - vX[2]^2/4
dB <- 2*vX[1] - exp(vX[2])
dOut <- sin(dA)*cos(dB)
return(dOut)
}
# plot it
vX <- seq(-0.5, 3, .1)
vY <- seq(-0.5, 2, .1)
dXYZ <- data.frame(matrix(0, nrow = length(vX)*length(vY), ncol = 3))
names(dXYZ) <- c('x', 'y', 'z')
n <- 0
for (i in 1:length(vX)) {
for (j in 1:length(vY)) {
n <- n + 1
dXYZ[n,] <- c(vX[i], vY[j], f1(c(vX[i], vY[j])))
}
}
library(lattice)
print(wireframe(z ~ x*y, data = dXYZ, shade = TRUE, scales = list(arrows = FALSE),
zlab = 'f(x, y)', drape = T))
# Root-finding and optimization
f <- function(dX) {
dOut = dX^3/3-dX
return(dOut)
}
f_prime <- function(dX) {
dOut = dX^2 - 1
return(dOut)
}
r1 <- optimize(f, lower = -2, upper = 2, maximum = TRUE)$maximum
r2 <- optimize(f, lower = -2, upper = 2)$minimum
#alternatively with root finding
#r1 <- uniroot(f_prime, lower = -2, upper = 0)$root
#r2 <- uniroot(f_prime, lower = 0, upper = 2)$root
vX <- (seq(-2, 2, 0.01))
plot(vX, f(vX), type = "l", ylim = c(-0.8,0.8))
abline(v = r1, col = "red")
abline(v = r2, col = "red")
plot(vX, f_prime(vX), type = "l")
abline(h = 0, col = "blue")
abline(v = r1, col = "red")
abline(v = r2, col = "red")
# Newton's method for optimization: Example
f <- function(dX) {
dOut = 2 * dX * (dX - 1)^2 * (dX + 2)
return(dOut)
}
vX <- seq(-2, 2, 0.001)
plot(vX, f(vX), type = "l")
f_prime <- function(dX) {
dOut = 4 - 12 * dX + 8 * dX^3
return(dOut)
}
f_sec <- function(dX) {
dOut = 24 * dX^2 - 12
return(dOut)
}
#Newton's method function
NM <- function(f, f_prime, f_sec, dX0, dTol = 1e-9, n.max = 1000){
dX <- dX0
fx <- f(dX)
fpx <- f_prime(dX)
fsx <- f_sec(dX)
n <- 0
while ((abs(fpx) > dTol) && (n < n.max)) {
dX <- dX - fpx/fsx
fx <- f(dX)
fpx <- f_prime(dX)
fsx <- f_sec(dX)
n <- n + 1
cat("At iteration", n, "the value of x is:", dX, "\n")
}
if (n == n.max) {
cat('newton failed to converge\n')
} else {
return(dX)
}
}
# x0 = -2
NM(f, f_prime, f_sec, dX0 = -2)
plot(vX, f(vX), type = "l")
abline(v = -2, col = "blue") #initial value x_0
abline(v = -1.5714286, lty = 2) #x_1
abline(v = -1.3982235, lty = 2) #x_2
abline(v = -1.367014, lty = 2) #x_3
abline(v = -1.3660264, lty = 2) #x_4
abline(v = -1.3660254, col = "red") #x_5 final value
# x0 = 1.5
NM(f, f_prime, f_sec, dX0 = 1.5)
plot(vX, f(vX), type = "l")
abline(v = 1.5, col = "blue") #initial value x_0
abline(v = 1.19047619047619, lty = 2) #x_1
abline(v = 1.04457786410815, lty = 2) #x_2
abline(v = 1.00346150187496, lty = 2) #x_3
abline(v = 1.00002369070203, lty = 2) #x_4
abline(v = 1.00000000112241, lty = 2) #x_5
abline(v = 1, col = "red") #x_6 final value
# x0 = -0.4
NM(f, f_prime, f_sec, dX0 = -0.4)
plot(vX, f(vX), type = "l")
abline(v = -0.4, col = "blue") #initial value x_0
abline(v = 0.61568627, lty = 2) #x_1
abline(v = 0.091579154, lty = 2) #x_2
abline(v = 0.33797834, lty = 2) #x_3
abline(v = 0.36531716, lty = 2) #x_4
abline(v = 0.3660249, lty = 2) #x_5
abline(v = 0.3660254, col = "red") #x_6 final value
### Golden-section Eample
# Golden-section function:
# applies the golden-section algorithm to maximise ftn
# we assume that ftn is a function of a single variable
# and that x.l < x.m < x.r and ftn(x.l), ftn(x.r) <= ftn(x.m)
#
# the algorithm iteratively refines x.l, x.r, and x.m and terminates
# when x.r - x.l <= tol, then returns x.m
# golden ratio plus one
gsection <- function(f, dX.l, dX.r, dX.m, dTol = 1e-9) {
# golden ratio plus one
dGR1 <- 1 + (1 + sqrt(5))/2
# successively refine x.l, x.r, and x.m
f.l <- f(dX.l)
f.r <- f(dX.r)
f.m <- f(dX.m)
while ((dX.r - dX.l) > dTol) {
if ((dX.r - dX.m) > (dX.m - dX.l)) {
dY <- dX.m + (dX.r - dX.m)/dGR1
f.y <- f(dY)
if (f.y >= f.m) {
dX.l <- dX.m
f.l <- f.m
dX.m <- dY
f.m <- f.y
} else {
dX.r <- dY
f.r <- f.y
}
} else {
dY <- dX.m - (dX.m - dX.l)/dGR1
f.y <- f(dY)
if (f.y >= f.m) {
dX.r <- dX.m
f.r <- f.m
dX.m <- dY
f.m <- f.y
} else {
dX.l <- dY
f.l <- f.y
}
}
}
return(dX.m)
}
gsection(f, dX.l = -1, dX.r = 1, dX.m = -0.5)
optimize(f, lower = -0.4, upper = 0.8, maximum = TRUE)
############# MULTI DIM ###################
## steepest ascend method
ascent <- function(f, grad.f, vX0, dTol = 1e-9, n.max = 100) {
vX.old <- vX0
vX <- line.search(f, vX0, grad.f(vX0))
n <- 1
while ((f(vX) - f(vX.old) > dTol) & (n < n.max)) {
vX.old <- vX
vX <- line.search(f, vX, grad.f(vX))
cat("at iteration", n, "the coordinates of x are", vX, "\n")
n <- n + 1
}
return(vX)
}
#line search
line.search <- function(f, vX, vY, dTol = 1e-9, dA.max = 2^5) {
# f is a real function that takes a vector of length d
# x and y are vectors of length d
# line.search uses gsection to find a >= 0 such that
# g(a) = f(x + a*y) has a local maximum at a,
# within a tolerance of tol
# if no local max is found then we use 0 or a.max for a
# the value returned is x + a*y
if (sum(abs(vY)) == 0) return(vX) # g(a) constant
g <- function(dA) return(f(vX + dA*vY))
# find a triple a.l < a.m < a.r such that
# g(a.l) <= g(a.m) and g(a.m) >= g(a.r)
# a.l
dA.l <- 0
g.l <- g(dA.l)
# a.m
dA.m <- 1
g.m <- g(dA.m)
while ((g.m < g.l) & (dA.m > dTol)) {
dA.m <- dA.m/2
g.m <- g(dA.m)
}
# if a suitable a.m was not found then use 0 for a
if ((dA.m <= dTol) & (g.m < g.l)) return(vX)
# a.r
dA.r <- 2*dA.m
g.r <- g(dA.r)
while ((g.m < g.r) & (dA.r < dA.max)) {
dA.m <- dA.r
g.m <- g.r
dA.r <- 2*dA.m
g.r <- g(dA.r)
}
# if a suitable a.r was not found then use a.max for a
if ((dA.r >= dA.max) & (g.m < g.r)) return(vX + dA.max*vY)
# apply golden-section algorithm to g to find a
dA <- gsection(g, dA.l, dA.r, dA.m)
return(vX + dA*vY)
}
### Example
f <- function(vX) {
dOut = sin(vX[1]^2/2 - vX[2]^2/4) * cos(2*vX[1] - exp(vX[2]))
return(dOut)
}
library(numDeriv)
grad.f <- function(vX) {
dX_prime.1 = cos(vX[1]^2/2 - vX[2]^2/4)*vX[1] * cos(2*vX[1] - exp(vX[2]))
dX_prime.2 = sin(vX[1]^2/2 - vX[2]^2/4) * (-sin(2*vX[1] - exp(vX[2]))*2)
dY_prime.1 = cos(vX[1]^2/2 - vX[2]^2/4)*(-vX[2]/2) * cos(2*vX[1] - exp(vX[2]))
dY_prime.2 = sin(vX[1]^2/2 - vX[2]^2/4) * sin(2*vX[1] - exp(vX[2]))*exp(vX[2])
vOut = c(dX_prime.1 + dX_prime.2, dY_prime.1 + dY_prime.2)
return(vOut)
}
grad(f, c(0, 0.5))
grad.f(c(0, 0.5))
ascent(f, grad.f, vX0 = c(0.1, 0.3))
ascent(f, grad.f, vX0 = c(0, 0.5))
newton <- function(f3, vX0, dTol = 1e-9, n.max = 100) {
# Newton's method for optimisation, starting at x0
# f3 is a function that given x returns the list
# {f(x), grad f(x), Hessian f(x)}, for some f
vX <- vX0
f3.x <- f3(vX)
n <- 0
while ((max(abs(f3.x[[2]])) > dTol) & (n < n.max)) {
vX <- vX - solve(f3.x[[3]], f3.x[[2]])
f3.x <- f3(vX)
cat("At iteration", n, "the coordinates of x are", vX, "\n")
n <- n + 1
}
if (n == n.max) {
cat('newton failed to converge\n')
} else {
return(vX)
}
}
f3 <- function(vX) {
dA <- vX[1]^2/2 - vX[2]^2/4
dB <- 2*vX[1] - exp(vX[2])
f <- sin(dA)*cos(dB)
f1 <- cos(dA)*cos(dB)*vX[1] - sin(dA)*sin(dB)*2
f2 <- -cos(dA)*cos(dB)*vX[2]/2 + sin(dA)*sin(dB)*exp(vX[2])
f11 <- -sin(dA)*cos(dB)*(4 + vX[1]^2) + cos(dA)*cos(dB) -
cos(dA)*sin(dB)*4*vX[1]
f12 <- sin(dA)*cos(dB)*(vX[1]*vX[2]/2 + 2*exp(vX[2])) +
cos(dA)*sin(dB)*(vX[1]*exp(vX[2]) + vX[2])
f22 <- -sin(dA)*cos(dB)*(vX[2]^2/4 + exp(2*vX[2])) - cos(dA)*cos(dB)/2 -
cos(dA)*sin(dB)*vX[2]*exp(vX[2]) + sin(dA)*sin(dB)*exp(vX[2])
return(list(f, c(f1, f2), matrix(c(f11, f12, f12, f22), 2, 2)))
}
newton(f3, vX0 = c(1.6, 0.5))
newton(f3, vX0 = c(1.75, 0.25))
newton(f3, vX0 = c(1.6, 1.2))
f1 <- function(vX) {
dA <- vX[1]^2/2 - vX[2]^2/4
dB <- 2*vX[1] - exp(vX[2])
dOut <- sin(dA)*cos(dB)
return(dOut)
}
vX <- seq(-0.5, 3, .1)
vY <- seq(-0.5, 2, .1)
dXYZ <- data.frame(matrix(0, nrow = length(vX)*length(vY), ncol = 3))
names(dXYZ) <- c('x', 'y', 'z')
n <- 0
for (i in 1:length(vX)) {
for (j in 1:length(vY)) {
n <- n + 1
dXYZ[n,] <- c(vX[i], vY[j], f1(c(vX[i], vY[j])))
}
}
library(lattice)
print(wireframe(z ~ x*y, data = dXYZ, shade = TRUE, scales = list(arrows = FALSE),
zlab = 'f(x, y)', drape = T))
